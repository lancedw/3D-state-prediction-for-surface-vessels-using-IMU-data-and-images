{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitch & Roll prediction w/Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import cv2\n",
    "import json\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import multiprocessing\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n",
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(pl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "CPU count: 4\n",
      "Platform: windows\n",
      "number of workers: 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\", device)\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "print('CPU count:', cpu_count)\n",
    "platform_os = \"windows\" if platform.system() == \"Windows\" else \"linux\"\n",
    "print(\"Platform:\", platform_os)\n",
    "\n",
    "# Pytorch Dataloader can't handle n_workers > 0 on windows due to bugs\n",
    "N_WORKERS = 0 if platform_os==\"windows\" else cpu_count\n",
    "print(f\"number of workers: {N_WORKERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to appropriate location\n",
    "TRAIN_FOLDER = \"../3dmodel/test_4_episode_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMES_IN = 1\n",
    "FRAMES_OUT = 10\n",
    "\n",
    "N_EPISODES = 540\n",
    "FRAMES_PER_EPISODE = 400\n",
    "SEQUENCE_LENGTH = 50\n",
    "\n",
    "TRAIN_SIZE = 0.8\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "CUDA = device.type == 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.915869</td>\n",
       "      <td>2.358416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.295925</td>\n",
       "      <td>1.700391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.213590</td>\n",
       "      <td>1.611325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.235337</td>\n",
       "      <td>6.175461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.341678</td>\n",
       "      <td>3.695468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pitch      roll\n",
       "0  15.915869  2.358416\n",
       "1  14.295925  1.700391\n",
       "2   6.213590  1.611325\n",
       "3   1.235337  6.175461\n",
       "4   1.341678  3.695468"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view first episode 's datapoints\n",
    "filename = TRAIN_FOLDER + \"1/\"\n",
    "data = []\n",
    "labels = json.load(open(filename+\"labels_0.json\"))\n",
    "ep1 = pd.DataFrame(labels)\n",
    "ep1 = ep1.transpose()\n",
    "ep1.rename(columns = {0:'pitch', 1:'roll'}, inplace=True)\n",
    "ep1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.915869</td>\n",
       "      <td>2.358416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.295925</td>\n",
       "      <td>1.700391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.213590</td>\n",
       "      <td>1.611325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.235337</td>\n",
       "      <td>6.175461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.341678</td>\n",
       "      <td>3.695468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pitch      roll\n",
       "0  15.915869  2.358416\n",
       "1  14.295925  1.700391\n",
       "2   6.213590  1.611325\n",
       "3   1.235337  6.175461\n",
       "4   1.341678  3.695468"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensors_array = []\n",
    "filename = TRAIN_FOLDER + \"1/\"\n",
    "for index, row in ep1.iterrows():\n",
    "    img = cv2.imread(filename + str(index) + \".png\")\n",
    "    img_tensors_array.append(torch.Tensor(img))\n",
    "ep1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, torch.Size([54, 96, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_tensors_array), img_tensors_array[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize pixels\n",
    "def norm_pixel(x):\n",
    "    x = x.astype('float32')\n",
    "    return (x*2)/255-1\n",
    "\n",
    "# Function to denormalize pixels\n",
    "def denorm_pixel(x):\n",
    "    x = x.astype('float32')\n",
    "    return (x+1)*255/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize pitch and roll angles\n",
    "def norm_pr(x, min = -90.0, max = 90.0):\n",
    "    return ((x - min) * 2) / (max - min) - 1\n",
    "\n",
    "# Function to denormalize pitch and roll angles\n",
    "def denorm_pr(x, min = -90.0, max = 90.0):\n",
    "    return ((x + 1) * (max - min))/2 + min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d57a1317fb47939340b9c7941c2443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(216000, torch.Size([54, 96, 3]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all data\n",
    "episodes_data = []\n",
    "img_tensors_array = []\n",
    "\n",
    "for ep in tqdm(range(1, N_EPISODES+1)):\n",
    "    folder = TRAIN_FOLDER + str(ep) + \"/\"\n",
    "    filename = folder + \"labels_0.json\"\n",
    "    labels = json.load(open(filename))\n",
    "    for i in labels:\n",
    "        # load image, normalize and convert to tensor\n",
    "        img = cv2.imread(folder + str(i) + \".png\")\n",
    "        img = norm_pixel(img)\n",
    "        img_tensors_array.append(torch.Tensor(img))\n",
    "\n",
    "        # pitch and roll is read with labels[i] as [pitch, roll]\n",
    "        episodes_data.append(labels[i])\n",
    "\n",
    "# verify that 216.000 images were loaded\n",
    "len(img_tensors_array), img_tensors_array[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.176843</td>\n",
       "      <td>0.026205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.158844</td>\n",
       "      <td>0.018893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069040</td>\n",
       "      <td>0.017904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013726</td>\n",
       "      <td>0.068616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014908</td>\n",
       "      <td>0.041061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pitch      roll\n",
       "0  0.176843  0.026205\n",
       "1  0.158844  0.018893\n",
       "2  0.069040  0.017904\n",
       "3  0.013726  0.068616\n",
       "4  0.014908  0.041061"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build dataframe with pitch and roll, cast as float and normalize\n",
    "p_r_df = pd.DataFrame(episodes_data)\n",
    "p_r_df.rename(columns = {0:'pitch', 1:'roll'}, inplace=True)\n",
    "p_r_df = p_r_df.astype({\"pitch\": float, \"roll\": float})\n",
    "p_r_df['pitch'] = p_r_df['pitch'].apply(lambda x : norm_pr(x))\n",
    "p_r_df['roll'] = p_r_df['roll'].apply(lambda x : norm_pr(x))\n",
    "print(p_r_df.shape)\n",
    "p_r_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([216000, 54, 96, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tranform the array of image tensors into one tensor of shape: (samples, height, width, channels)\n",
    "img_tensor = torch.stack(img_tensors_array)\n",
    "img_tensor_array = None # free this memory\n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1901"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create input and output sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create sequences with one target column\n",
    "def create_sequences(\n",
    "        input_data: pd.DataFrame, \n",
    "        input_images,\n",
    "        input_feature_columns,\n",
    "        output_target_columns, \n",
    "        input_sequence_length=FRAMES_IN, \n",
    "        output_sequence_length=FRAMES_OUT,  \n",
    "        episode_length = FRAMES_PER_EPISODE, \n",
    "        n_episodes = N_EPISODES\n",
    "    ):\n",
    "    sequences= []\n",
    "\n",
    "    # make sequences per episode, one sequence can only hold data of one and the same episode!\n",
    "    for n in tqdm(range(n_episodes)):\n",
    "\n",
    "        for l in range(episode_length-output_sequence_length-input_sequence_length+1):\n",
    "            \n",
    "            i = l+(n*episode_length)\n",
    "\n",
    "            # grab image input tensors from list with img_tensors\n",
    "            sequence = input_images[i:i+input_sequence_length]\n",
    "\n",
    "            # grab pr output sequence from dataframe\n",
    "            target_position = i + input_sequence_length\n",
    "            target = input_data.iloc[target_position:target_position+output_sequence_length]\n",
    "\n",
    "            sequences.append((sequence, target))\n",
    "\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70abff30d0f54563802a89d505fe5a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use images to predict pitch and roll\n",
    "input_features = []\n",
    "output_features = [\"pitch\", \"roll\"]\n",
    "all_sequences = create_sequences(p_r_df, img_tensor, input_features, output_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210600, torch.Size([1, 54, 96, 3]), (10, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sequences), all_sequences[0][0].shape , all_sequences[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 54, 96, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first input sequence\n",
    "all_sequences[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.158844</td>\n",
       "      <td>0.018893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069040</td>\n",
       "      <td>0.017904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013726</td>\n",
       "      <td>0.068616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014908</td>\n",
       "      <td>0.041061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000724</td>\n",
       "      <td>0.034174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pitch      roll\n",
       "1  0.158844  0.018893\n",
       "2  0.069040  0.017904\n",
       "3  0.013726  0.068616\n",
       "4  0.014908  0.041061\n",
       "5 -0.000724  0.034174"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first output sequence\n",
    "all_sequences[0][1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ni = 0\\nfor data in tqdm(all_sequences):\\n    input = data[0]\\n    output = data[1]\\n\\n    episode = input.iloc[0][\"episode\"]\\n    episode1 = output.iloc[0][\"episode\"]\\n    \\n    if(episode1 != episode):\\n        print(\"Input and output from different episodes\")\\n        break\\n\\n    if (len(input[\\'episode\\'].unique()) != 1):\\n        print(\"input seq: \"+i+\" contains data from different episodes\")\\n        break\\n    \\n    if (len(output[\\'episode\\'].unique()) != 1):\\n        print(\"output seq: \"+i+\" contains data from different episodes\")\\n        break\\n    \\n    i += 1\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop for testing sequence integrity\n",
    "\"\"\"\n",
    "i = 0\n",
    "for data in tqdm(all_sequences):\n",
    "    input = data[0]\n",
    "    output = data[1]\n",
    "\n",
    "    episode = input.iloc[0][\"episode\"]\n",
    "    episode1 = output.iloc[0][\"episode\"]\n",
    "    \n",
    "    if(episode1 != episode):\n",
    "        print(\"Input and output from different episodes\")\n",
    "        break\n",
    "\n",
    "    if (len(input['episode'].unique()) != 1):\n",
    "        print(\"input seq: \"+i+\" contains data from different episodes\")\n",
    "        break\n",
    "    \n",
    "    if (len(output['episode'].unique()) != 1):\n",
    "        print(\"output seq: \"+i+\" contains data from different episodes\")\n",
    "        break\n",
    "    \n",
    "    i += 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "168480 42120\n",
      "[167621, 29184, 6556, 194393, 72097, 64196, 58513, 36579, 193061, 26868]\n",
      "[131073, 3, 4, 131078, 7, 8, 131083, 131088, 131089, 131090]\n"
     ]
    }
   ],
   "source": [
    "# Grab random subsets from all sequences for training and test data (without overlapping data)\n",
    "data_size = len(all_sequences)\n",
    "data_indices = list(np.arange(0, data_size, 1))\n",
    "\n",
    "# train indices are random sample from all data indices\n",
    "random.seed(42)\n",
    "train_size = int(TRAIN_SIZE * data_size)\n",
    "train_indices = random.sample(data_indices, train_size)\n",
    "\n",
    "# test indices are the difference of all data indices and train indices\n",
    "test_indices = list(set(data_indices) - set(train_indices))\n",
    "\n",
    "print((len(train_indices) + len(test_indices)) <= data_size)\n",
    "print(\"Training size:\", len(train_indices),\"| Test size:\", len(test_indices))\n",
    "print(train_indices[:10])\n",
    "print(test_indices[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84fda8252774083b80ed11ef836644e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb08a065729446ac8099b171942544f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "168480 torch.Size([1, 54, 96, 3]) (10, 2)\n",
      "42120 torch.Size([1, 54, 96, 3]) (10, 2)\n"
     ]
    }
   ],
   "source": [
    "train_sequences = []\n",
    "test_sequences = []\n",
    "\n",
    "for idx in tqdm(train_indices):\n",
    "    seq = all_sequences[idx][0]\n",
    "    label = all_sequences[idx][1]\n",
    "    train_sequences.append((seq,label))\n",
    "\n",
    "for idx in tqdm(test_indices):\n",
    "    seq = all_sequences[idx][0]\n",
    "    label = all_sequences[idx][1]\n",
    "    test_sequences.append((seq,label))\n",
    "\n",
    "print((len(train_sequences) + len(test_sequences)) <= len(all_sequences))\n",
    "print(len(train_sequences), train_sequences[0][0].shape, train_sequences[0][1].shape) \n",
    "print(len(test_sequences), test_sequences[0][0].shape, test_sequences[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sequence, labels = self.sequences[index]\n",
    "\n",
    "        return dict(\n",
    "            sequence = sequence,\n",
    "            labels = torch.Tensor(labels.to_numpy())\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_sequences, test_sequences, batchsize = BATCH_SIZE):\n",
    "        super().__init__()\n",
    "        self.train_sequences = train_sequences\n",
    "        self.test_sequences = test_sequences\n",
    "        self.batchsize = batchsize\n",
    "\n",
    "    # turns normal list object into Dataset object\n",
    "    def setup(self):\n",
    "        self.train_dataset = PRDataset(self.train_sequences)\n",
    "        self.test_dataset = PRDataset(self.test_sequences)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size = self.batchsize,\n",
    "            shuffle = False,\n",
    "            num_workers=N_WORKERS,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size = self.batchsize,\n",
    "            shuffle = False,\n",
    "            num_workers=N_WORKERS,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size = 1,\n",
    "            shuffle = False,\n",
    "            num_workers=N_WORKERS,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = PRDataModule(train_sequences, test_sequences, BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 54, 96, 3])\n",
      "torch.Size([64, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "# batch size first\n",
    "for batch in data_module.train_dataloader():\n",
    "    print(batch[\"sequence\"].shape)\n",
    "    print(batch[\"labels\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Sequence(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(CNN_Sequence, self).__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CNN_Sequence'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_Sequence(2).__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_stack_FC_first(nn.Module):\n",
    "    def __init__(self, cuda = True, num_channel = 3,  cnn_fc_size = 1024, num_output=20):\n",
    "        super(CNN_stack_FC_first, self).__init__()\n",
    "        self.cuda_p = cuda\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(num_channel, 8, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding = 1)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(5376  , cnn_fc_size) #5376 / 20736\n",
    "        self.fc2 = nn.Linear(cnn_fc_size, 128)\n",
    "        self.fc3 = nn.Linear(128, num_output)\n",
    "        self.dropout0 = nn.Dropout(p=0.3)\n",
    "        self.dropout1 = nn.Dropout(p=0.4)\n",
    "        self.dropout2 = nn.Dropout(p= 0.4)\n",
    "\n",
    "\n",
    "    def forward(self, x, p_and_roll, num_images):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout0(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x =  torch.tanh(self.fc3(x)).view(x.size(0), -1, 2)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 54, 96, 3]) torch.Size([64, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "# get the first batch out of the dataloader for testing purposes\n",
    "for batch in data_module.train_dataloader():\n",
    "    x_train = batch[\"sequence\"]\n",
    "    y_train = batch[\"labels\"]\n",
    "    break\n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e337f12075b14d5aa2a6fc55811e5513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (30) must match the size of tensor b (64) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\1 Documenten\\2021-2022 Industrieel Ir\\Thesis\\Thesis\\code\\notebooks\\pr_sequence_predictor.ipynb Cell 36'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1%20Documenten/2021-2022%20Industrieel%20Ir/Thesis/Thesis/code/notebooks/pr_sequence_predictor.ipynb#ch0000034?line=18'>19</a>\u001b[0m     y_train \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1%20Documenten/2021-2022%20Industrieel%20Ir/Thesis/Thesis/code/notebooks/pr_sequence_predictor.ipynb#ch0000034?line=20'>21</a>\u001b[0m \u001b[39m# Predict on forward pass \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/1%20Documenten/2021-2022%20Industrieel%20Ir/Thesis/Thesis/code/notebooks/pr_sequence_predictor.ipynb#ch0000034?line=21'>22</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(x_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1%20Documenten/2021-2022%20Industrieel%20Ir/Thesis/Thesis/code/notebooks/pr_sequence_predictor.ipynb#ch0000034?line=22'>23</a>\u001b[0m \u001b[39mif\u001b[39;00m CUDA: \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1%20Documenten/2021-2022%20Industrieel%20Ir/Thesis/Thesis/code/notebooks/pr_sequence_predictor.ipynb#ch0000034?line=23'>24</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mcuda()\n",
      "\u001b[1;32md:\\1 Documenten\\2021-2022 Industrieel Ir\\Thesis\\Thesis\\code\\notebooks\\pr_sequence_predictor.ipynb Cell 33'\u001b[0m in \u001b[0;36mPRPredictionModel.forward\u001b[1;34m(self, x, future)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1%20Documenten/2021-2022%20Industrieel%20Ir/Thesis/Thesis/code/notebooks/pr_sequence_predictor.ipynb#ch0000031?line=28'>29</a>\u001b[0m outputs\u001b[39m.\u001b[39mappend(out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1%20Documenten/2021-2022%20Industrieel%20Ir/Thesis/Thesis/code/notebooks/pr_sequence_predictor.ipynb#ch0000031?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(future\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/1%20Documenten/2021-2022%20Industrieel%20Ir/Thesis/Thesis/code/notebooks/pr_sequence_predictor.ipynb#ch0000031?line=31'>32</a>\u001b[0m     output, (hidden_state, cell_state) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x \u001b[39m+\u001b[39;49m out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1%20Documenten/2021-2022%20Industrieel%20Ir/Thesis/Thesis/code/notebooks/pr_sequence_predictor.ipynb#ch0000031?line=32'>33</a>\u001b[0m     out \u001b[39m=\u001b[39m hidden_state[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1%20Documenten/2021-2022%20Industrieel%20Ir/Thesis/Thesis/code/notebooks/pr_sequence_predictor.ipynb#ch0000031?line=33'>34</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregressor(out)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (30) must match the size of tensor b (64) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "model = CNN_Sequence(2)\n",
    "\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# TRACKERS\n",
    "train_losses_epoch = []\n",
    "val_losses_epoch = []\n",
    "train_losses_all_batches = []   # list with (epoch nr, [losses from all batches]) tuples\n",
    "\n",
    "n_epochs = NUM_EPOCHS\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "\n",
    "    losses_current_batch = []\n",
    "\n",
    "    for batch in data_module.train_dataloader():\n",
    "        x_train = batch[\"sequence\"]\n",
    "        y_train = batch[\"labels\"]\n",
    "\n",
    "        if CUDA: \n",
    "            x_train = batch[\"sequence\"].cuda()\n",
    "            y_train = batch[\"labels\"].cuda()\n",
    "        \n",
    "        # Predict on forward pass \n",
    "        y_pred = model.forward(x_train)\n",
    "        if CUDA: \n",
    "            y_pred = y_pred.cuda()\n",
    "\n",
    "        # Calculate loss/error\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        losses_current_batch.append(loss)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # add batch-losses to dictionary\n",
    "    train_losses_all_batches.append((epoch, losses_current_batch))\n",
    "\n",
    "    train_losses_epoch.append(loss.item())\n",
    "    train_loss = round(loss.item(), 6)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_module.val_dataloader():\n",
    "            x_val = batch[\"sequence\"]\n",
    "            y_val = batch[\"labels\"]\n",
    "\n",
    "            if CUDA: \n",
    "                x_val = batch[\"sequence\"].cuda()\n",
    "                y_val = batch[\"labels\"].cuda()\n",
    "            \n",
    "            # Predict on forward pass \n",
    "            y_pred = model.forward(x_val)\n",
    "            if CUDA: \n",
    "                y_pred = y_pred.cuda()\n",
    "            \n",
    "        loss = criterion(y_pred, y_val)\n",
    "        val_losses_epoch(loss.item())\n",
    "        val_loss = round(loss.item(), 6)\n",
    "\n",
    "    print(f\"EPOCH {epoch} training loss: {train_loss} | validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(range(n_epochs), train_losses_epoch, label='training loss')\n",
    "plt.plot(range(n_epochs), val_losses_epoch, label='validation loss')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'model_states/CNN_img-to-PR_{FRAMES_IN}in_{FRAMES_OUT}out_epochs{NUM_EPOCHS}'\n",
    "torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRPredictionModel(\n",
       "  (lstm): LSTM(2, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (regressor): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = f'model_states/CNN_img-to-PR_{FRAMES_IN}in_{FRAMES_OUT}out_epochs{NUM_EPOCHS}'\n",
    "loaded_model = CNN_Sequence(FRAMES_IN)\n",
    "loaded_model.load_state_dict(torch.load('model_states/PR_LSTM_sequence'))\n",
    "if CUDA: \n",
    "    loaded_model = loaded_model.cuda()\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 2]) torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# get first I/O-sequence of test dataset for visualizing a prediction\n",
    "for batch in data_module.test_dataloader():\n",
    "    x_test = batch[\"sequence\"]\n",
    "    y_test = batch[\"labels\"]\n",
    "    break\n",
    "\n",
    "if CUDA:\n",
    "    x_test = x_test.cuda()\n",
    "    y_test = y_test.cuda()\n",
    "\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\ttensor([[0.2471, 0.1820]], device='cuda:0')\n",
      "real:\t\ttensor([[0.2538, 0.1659]], device='cuda:0')\n",
      "loss: 0.0001526541163912043\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "# make one prediction for visualization\n",
    "with torch.no_grad():\n",
    "    y_pred = loaded_model(x_test)\n",
    "    loss = criterion(y_pred, y_test)\n",
    "\n",
    "    # clean up tensor and round results to visually compare predicted sequence\n",
    "    a = y_pred.squeeze(0)[0].tolist()\n",
    "    a = [round(num, 4) for num in a]\n",
    "\n",
    "    b = y_test.squeeze(0)[0].tolist()\n",
    "    b = [round(num, 4) for num in b]\n",
    "\n",
    "    print(f'predicted pitch: {a}\\nreal pitch:\\t {b}')\n",
    "    print(\"loss:\", round(loss.item(), 6))\n",
    "\n",
    "# squeeze out batch size and convert into cpu format for plotting\n",
    "x_test.squeeze(0).shape\n",
    "input_sequence = x_test.squeeze(0).cpu()\n",
    "output_sequence = y_test.squeeze(0).cpu()\n",
    "predicted_sequence = y_pred.squeeze(0).cpu()\n",
    "input_sequence.shape, output_sequence.shape, predicted_sequence.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction vs. real on first test I/O-sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.arange(0,FRAMES_IN+FRAMES_OUT)\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "ax.plot(frames, torch.cat((input_sequence[0], output_sequence[0])), label=\"real\")\n",
    "ax.plot(frames[FRAMES_IN:], predicted_sequence[0], color=\"red\", label='predicted')\n",
    "plt.axvline(x=FRAMES_IN, color='grey', linestyle='dotted')\n",
    "ax.set_xlabel('frames')\n",
    "ax.set_ylabel('pitch (normalized)')\n",
    "ax.set_title('30 to 10 prediction results')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.arange(0,FRAMES_IN+FRAMES_OUT)\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "ax.plot(frames, torch.cat((input_sequence[1], output_sequence[1])), label=\"real\")\n",
    "ax.plot(frames[FRAMES_IN:], predicted_sequence[1], color=\"red\", label='predicted')\n",
    "plt.axvline(x=FRAMES_IN, color='grey', linestyle='dotted')\n",
    "ax.set_xlabel('frames')\n",
    "ax.set_ylabel('roll (normalized)')\n",
    "ax.set_title('30 to 10 prediction results')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d06a2554e64723a58bf391f60b1f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(data_module.test_dataloader()):\n",
    "        x_test = batch[\"sequence\"]\n",
    "        y_test = batch[\"labels\"]\n",
    "\n",
    "        if CUDA:\n",
    "            x_test = x_test.cuda()\n",
    "            y_test = y_test.cuda()\n",
    "\n",
    "        output = loaded_model(x_test)\n",
    "        predictions.append(output.detach().to('cpu').numpy().flatten())\n",
    "        labels.append(y_test.detach().to('cpu').numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions[0] = np array object\n",
    "# Predictions[0][0] = pitch value\n",
    "# Predictions[0][1] = roll value\n",
    "\n",
    "pitch_predictions = []\n",
    "roll_predictions = []\n",
    "\n",
    "pitch_label = []\n",
    "roll_label = []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    pitch_predictions.append(predictions[i][0])\n",
    "    roll_predictions.append(predictions[i][1])\n",
    "    pitch_label.append(labels[i][0])\n",
    "    roll_label.append(labels[i][1])\n",
    "\n",
    "pitch_predictions[0].shape, roll_predictions[0].shape, pitch_label[0].shape, roll_label[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average loss-per-frame over all datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns a list with loss-values per frame\n",
    "def loss_per_frame(predicted_sequence, real_sequence):\n",
    "    loss_per_frame = []\n",
    "    criterion = nn.MSELoss()\n",
    "    if predicted_sequence.shape != real_sequence.shape:\n",
    "        return loss_per_frame\n",
    "    for i in range(len(predicted_sequence)):\n",
    "        loss = criterion(predicted_sequence[i], real_sequence[i])\n",
    "        loss_per_frame.append(loss.item())\n",
    "    return loss_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean loss per frame over all test data\n",
    "total = len(pitch_predictions)\n",
    "pitch_total = np.zeros(FRAMES_OUT, dtype=np.float64)\n",
    "roll_total = np.zeros(FRAMES_OUT, dtype=np.float64)\n",
    "\n",
    "for i in tqdm(range(len(pitch_predictions))):\n",
    "    pitch_lpf = loss_per_frame(pitch_predictions[i], pitch_label[i])\n",
    "    roll_lpf = loss_per_frame(roll_predictions[i], roll_label[i])\n",
    "    pitch_total += pitch_lpf\n",
    "    roll_total += roll_lpf\n",
    "\n",
    "pitch_lpf_mse = pitch_total / total\n",
    "roll_lpf_mse = roll_total / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(pitch_lpf_mse, label='pitch')\n",
    "plt.plot(roll_lpf_mse, color='orange', label='roll')\n",
    "plt.xlabel('predicted frame')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Loss per frame: MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_lpf_rmse = np.sqrt(pitch_lpf_mse)\n",
    "roll_lpf_rmse = np.sqrt(roll_lpf_mse)\n",
    "denorm = lambda x: denorm_pr(x)\n",
    "vfunc = np.vectorize(denorm)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(vfunc(pitch_lpf_rmse), label='pitch')\n",
    "plt.plot(vfunc(roll_lpf_rmse), color='orange', label='roll')\n",
    "plt.xlabel('predicted frame')\n",
    "plt.ylabel('Denormalized RMSE Loss ()')\n",
    "plt.title('Loss per frame: denormalized RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE results pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(pitch_predictions)\n",
    "loss0_tensor = torch.zeros(FRAMES_OUT)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = 0\n",
    "loss0 = 0\n",
    "\n",
    "for i in range(n):\n",
    "    loss += criterion(pitch_label[i], pitch_predictions[i]).item()\n",
    "    loss0 += criterion(pitch_label[i], loss0_tensor).item()\n",
    "\n",
    "mse = round(loss/n, 5)\n",
    "rmse = round(math.sqrt(loss/n), 4)\n",
    "mse0 = round(loss0/n, 5)\n",
    "rmse0 = round(math.sqrt(loss0/n), 4)\n",
    "\n",
    "print(\"Pitch prediction\")\n",
    "print(\"   MSE:\", mse)\n",
    "print(\"   RMSE:\", rmse)\n",
    "print(f\"   RMSE denorm: {round(denorm_pr(rmse), 2)}\")\n",
    "print(\"Zero prediction\")\n",
    "print(\"   MSE 0:\", mse0)\n",
    "print(\"   RMSE 0:\", rmse0)\n",
    "print(f\"   RMSE denorm: {round(denorm_pr(rmse0), 2)}\")\n",
    "print(\"Improvement on zero prediction:\")\n",
    "print(\"   MSE delta%:\", round(mse0/mse*100, 2), \"%\")\n",
    "print(\"   RMSE delta%:\", round(rmse0/rmse*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE results roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(pitch_predictions)\n",
    "loss0_tensor = torch.zeros(FRAMES_OUT)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = 0\n",
    "loss0 = 0\n",
    "\n",
    "for i in range(n):\n",
    "    loss += criterion(roll_label[i], roll_predictions[i]).item()\n",
    "    loss0 += criterion(roll_label[i], loss0_tensor).item()\n",
    "\n",
    "mse = round(loss/n, 5)\n",
    "rmse = round(math.sqrt(loss/n), 4)\n",
    "mse0 = round(loss0/n, 5)\n",
    "rmse0 = round(math.sqrt(loss0/n), 4)\n",
    "\n",
    "print(\"Roll prediction\")\n",
    "print(\"   MSE:\", mse)\n",
    "print(\"   RMSE:\", rmse)\n",
    "print(f\"   RMSE denorm: {round(denorm_pr(rmse), 2)}\")\n",
    "print(\"Zero prediction\")\n",
    "print(\"   MSE 0:\", mse0)\n",
    "print(\"   RMSE 0:\", rmse0)\n",
    "print(f\"   RMSE denorm: {round(denorm_pr(rmse0), 2)}\")\n",
    "print(\"Improvement on zero prediction:\")\n",
    "print(\"   MSE delta%:\", round(mse0/mse*100, 2), \"%\")\n",
    "print(\"   RMSE delta%:\", round(rmse0/rmse*100, 2), \"%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c1b2a501f02df7b26d92d459eb05316e48170af73a43fcdd672df666b3b816d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('Thesis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
